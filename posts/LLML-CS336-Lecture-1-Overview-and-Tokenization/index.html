

<!DOCTYPE html>
<html lang="en" >



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/YXY.png">
  <link rel="icon" href="/img/YXY.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#c30000">
  <meta name="author" content="Xiyuan Yang">
  <meta name="keywords" content="Code">
  
    <meta name="description" content="Lecture Notes for CS336: Lecture 1 Overview and Tokenization, as a part of tutorial for LLM Learning Plan as well.">
<meta property="og:type" content="article">
<meta property="og:title" content="LLML CS336 Lecture 1 Overview and Tokenization">
<meta property="og:url" content="https://xiyuanyang-code.github.io/posts/LLML-CS336-Lecture-1-Overview-and-Tokenization/index.html">
<meta property="og:site_name" content="Xiyuan Yang&#39;s Blog">
<meta property="og:description" content="Lecture Notes for CS336: Lecture 1 Overview and Tokenization, as a part of tutorial for LLM Learning Plan as well.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://xiyuanyang-code.github.io/img/cover/tokenize.jpg">
<meta property="article:published_time" content="2025-07-28T15:39:49.000Z">
<meta property="article:modified_time" content="2025-08-01T13:37:59.001Z">
<meta property="article:author" content="Xiyuan Yang">
<meta property="article:tag" content="Tutorial">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Tokenization">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://xiyuanyang-code.github.io/img/cover/tokenize.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>LLML CS336 Lecture 1 Overview and Tokenization - Xiyuan Yang&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.16.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xiyuanyang-code.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":50,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4","placement":"left","visible":"hover","icon":"❡"},"progressbar":{"enable":true,"height_px":3,"color":"red","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":2},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"L7r0uGb0fafbzNvmBADCMH42-gzGzoHsz","app_key":"2Lr1fQ2rjhwRiUrDx0VOQyUm","server_url":null,"path":"window.location.pathname","ignore_local":true},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Xiyuan Yang&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="https://xiyuanyang-code.github.io/posts/Above-All-en/" target="_self">
                <i class="iconfont icon-bookmark-fill"></i>
                <span>Intro</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archive</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Category</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="https://xiyuanyang-code.github.io/resume/" target="_self">
                <i class="iconfont icon-code"></i>
                <span>Resume</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-clipcheck"></i>
                <span>Record</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/Recordings/" target="_self">
                    <i class="iconfont icon-clipcheck"></i>
                    <span>Daily Loggings</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/ReadPaper/" target="_self">
                    <i class="iconfont icon-clipcheck"></i>
                    <span>Reading Papers</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>Else</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/FAQ/" target="_self">
                    <i class="iconfont icon-bug"></i>
                    <span>FAQ</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/links" target="_self">
                    <i class="iconfont icon-link-fill"></i>
                    <span>Links</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/tags/" target="_self">
                    <i class="iconfont icon-tags-fill"></i>
                    <span>Tag</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://xiyuanyang-code.github.io/Blog-word-counting/" target="_self">
                    <i class="iconfont icon-plan"></i>
                    <span>Word Counting</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://xiyuanyang-code.github.io/posts/My-Posts/" target="_self">
                    <i class="iconfont icon-notebook"></i>
                    <span>All Posts</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://github.com/xiyuanyang-code" target="_self">
                    <i class="iconfont icon-github-fill"></i>
                    <span>My Github</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/" target="_self">
                    <i class="iconfont icon-copyright"></i>
                    <span>About Hexo</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://xiyuanyang-code.github.io/posts/Life-musings/" target="_self">
                    <i class="iconfont icon-brush"></i>
                    <span>Life Musing</span>
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/place.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="LLML CS336 Lecture 1 Overview and Tokenization"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Xiyuan Yang
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-07-28 23:39" pubdate>
          July 28, 2025 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          1.3k words
        
      </span>
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Artificial Intelligence"
        id="heading-5cd2adc9e2a5254e4c1da803519f298b" role="tab" data-toggle="collapse" href="#collapse-5cd2adc9e2a5254e4c1da803519f298b"
        aria-expanded="true"
      >
        Artificial Intelligence
        <span class="list-group-count">(21)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-5cd2adc9e2a5254e4c1da803519f298b"
           role="tabpanel" aria-labelledby="heading-5cd2adc9e2a5254e4c1da803519f298b">
        
        
          
          
  <div class="category-post-list">
    
    
      
      
        <a href="/posts/Pre-training-Is-Dead/" title="Pre-Training-Is-Dead?"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Pre-Training-Is-Dead?</span>
        </a>
      
    
      
      
        <a href="/posts/RL-speeches/" title="RL_speeches"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">RL_speeches</span>
        </a>
      
    
      
      
        <a href="/posts/AI-Paper-2024/" title="AI-Paper-2024"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">AI-Paper-2024</span>
        </a>
      
    
      
      
        <a href="/posts/Factor-Mining-in-Quantitative-Investing-A-Survey/" title="Factor Mining in Quantitative Investing: A Survey"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Factor Mining in Quantitative Investing: A Survey</span>
        </a>
      
    
      
      
        <a href="/posts/The-New-Code-Sean-Grove-OpenAI/" title="The New Code: Sean Grove, OpenAI"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">The New Code: Sean Grove, OpenAI</span>
        </a>
      
    
  </div>

          
  
    
    
    
    <div class="category-sub row nomargin-x">
      <a class="category-subitem collapsed
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="CS294 LLM Agents"
        id="heading-031f1bdd6c7d4beec5865e47313ba4bf" role="tab" data-toggle="collapse" href="#collapse-031f1bdd6c7d4beec5865e47313ba4bf"
        aria-expanded="false"
      >
        CS294 LLM Agents
        <span class="list-group-count">(3)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse " id="collapse-031f1bdd6c7d4beec5865e47313ba4bf"
           role="tabpanel" aria-labelledby="heading-031f1bdd6c7d4beec5865e47313ba4bf">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/posts/CS294-1-LLM-Reasoning/" title="CS294-1-LLM-Reasoning"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">CS294-1-LLM-Reasoning</span>
        </a>
      
    
      
      
        <a href="/posts/CS294-3-Autogen/" title="CS294-3-Autogen"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">CS294-3-Autogen</span>
        </a>
      
    
      
      
        <a href="/posts/Agents-in-Coding-A-survey/" title="Agents in Coding: A Survey"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Agents in Coding: A Survey</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
    
    
    
    <div class="category-sub row nomargin-x">
      <a class="category-subitem collapsed
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Deep Learning"
        id="heading-6a68b6412b3d8a605c374d3c59e02694" role="tab" data-toggle="collapse" href="#collapse-6a68b6412b3d8a605c374d3c59e02694"
        aria-expanded="false"
      >
        Deep Learning
        <span class="list-group-count">(3)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse " id="collapse-6a68b6412b3d8a605c374d3c59e02694"
           role="tabpanel" aria-labelledby="heading-6a68b6412b3d8a605c374d3c59e02694">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/posts/Deep-Learning-Memo/" title="Deep Learning Memo"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Deep Learning Memo</span>
        </a>
      
    
      
      
        <a href="/posts/AIBasis-Neural-Networks/" title="AIBasis Neural Networks"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">AIBasis Neural Networks</span>
        </a>
      
    
      
      
        <a href="/posts/Imagenet/" title="ImageNet and ILSVRC"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">ImageNet and ILSVRC</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
    
    
    
    <div class="category-sub row nomargin-x">
      <a class="category-subitem 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="LLM"
        id="heading-b8cc08c142bcf05a92faec2d6ed58b05" role="tab" data-toggle="collapse" href="#collapse-b8cc08c142bcf05a92faec2d6ed58b05"
        aria-expanded="true"
      >
        LLM
        <span class="list-group-count">(7)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-b8cc08c142bcf05a92faec2d6ed58b05"
           role="tabpanel" aria-labelledby="heading-b8cc08c142bcf05a92faec2d6ed58b05">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/posts/RAG-tutorial/" title="RAG-Tutorial"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">RAG-Tutorial</span>
        </a>
      
    
      
      
        <a href="/posts/LLM-Evaluating/" title="LLM Evaluating"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">LLM Evaluating</span>
        </a>
      
    
      
      
        <a href="/posts/LLM-Learning-Initial/" title="LLM Learning Initial"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">LLM Learning Initial</span>
        </a>
      
    
      
      
        <a href="/posts/LLML-Attention/" title="Attention Mechanism"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Attention Mechanism</span>
        </a>
      
    
      
      
        <a href="/posts/LLML-Transformer/" title="LLM Transformer"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">LLM Transformer</span>
        </a>
      
    
      
      
        <a href="/posts/LLML-CS336-Lecture-1-Overview-and-Tokenization/" title="LLML CS336 Lecture 1 Overview and Tokenization"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">LLML CS336 Lecture 1 Overview and Tokenization</span>
        </a>
      
    
      
      
        <a href="/posts/LLML-CS336-Lecture-2-Pytorch-Resource-Accounting/" title="LLML CS336 Lecture 2 Pytorch Resource Accounting"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">LLML CS336 Lecture 2 Pytorch Resource Accounting</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
    
    
    
    <div class="category-sub row nomargin-x">
      <a class="category-subitem collapsed
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Torch"
        id="heading-a8b6ce53a1cdf2ee4d3f16b939029b2b" role="tab" data-toggle="collapse" href="#collapse-a8b6ce53a1cdf2ee4d3f16b939029b2b"
        aria-expanded="false"
      >
        Torch
        <span class="list-group-count">(3)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse " id="collapse-a8b6ce53a1cdf2ee4d3f16b939029b2b"
           role="tabpanel" aria-labelledby="heading-a8b6ce53a1cdf2ee4d3f16b939029b2b">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/posts/Torch-memo/" title="Torch-Memo"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Torch-Memo</span>
        </a>
      
    
      
      
        <a href="/posts/Torch-Memo-Tensor-Operations/" title="Torch Memo Tensor Operations"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Torch Memo Tensor Operations</span>
        </a>
      
    
      
      
        <a href="/posts/Torch-Memo-TensorBoard/" title="Torch Memo TensorBoard"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Torch Memo TensorBoard</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">LLML CS336 Lecture 1 Overview and Tokenization</h1>
            
            
              <div class="markdown-body">
                
                <h1>CS336: Lecture 1 Overview and Tokenization</h1>
<style>
  html, body, .markdown-body {
    font-family: Georgia, sans, serif;
  }
</style>
<h2 id="Course-Overview">Course Overview</h2>
<p><a target="_blank" rel="noopener" href="https://stanford-cs336.github.io/spring2025/">Course Information</a></p>
<p><strong>ALL FOCUSED ON EFFICIENCY</strong></p>
<p>The main 5 components for this course:</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/design-decisions.png" srcset="/img/loading.gif" lazyload alt="Course Components"></p>
<p>More descriptions about the course overview can be found in <a target="_blank" rel="noopener" href="https://stanford-cs336.github.io/spring2025-lectures/?trace=var%2Ftraces%2Flecture_01.json">Course Lecture Notes</a>.</p>
<h2 id="More-than-a-course-overview…">More than a course overview…</h2>
<p>What I will learn from this course?</p>
<p>Full understanding of this technology is necessary and crucial for fundamental search, rather than just calling a prompt.</p>
<div class="note note-info">
            <p>There are three types of knowledge:</p><ul><li><p>Mechanics: how things work (what a Transformer is, how model parallelism leverages GPUs)</p></li><li><p>Mindset: squeezing the most out of the hardware, taking scale seriously (scaling laws)</p></li><li><p>Intuitions: which data and modeling decisions yield good accuracy</p></li></ul><p>We can teach mechanics and mindset (these do transfer). We can only partially teach intuitions (do not necessarily transfer across scales).</p>
          </div>
<h3 id="About-Scaling-Law-The-bitter-lesson">About Scaling Law &amp; The bitter lesson</h3>
<p>Is the algorithm really making no sense? Of course not! We cannot afford to make it so wasteful!</p>
<ul>
<li>Wrong interpretation: scale is all that matters, algorithms don’t matter.</li>
<li>Right interpretation: <strong>algorithms that scale is what matters</strong>.</li>
</ul>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>accuracy</mtext><mo>=</mo><mtext>efficiency</mtext><mo>×</mo><mtext>resources</mtext></mrow><annotation encoding="application/x-tex">\text{accuracy} = \text{efficiency} \times \text{resources}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">accuracy</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">efficiency</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord text"><span class="mord">resources</span></span></span></span></span></span></p>
<p>In fact, efficiency is way more important at larger scale (can’t afford to be wasteful). In other words, maximize efficiency!</p>
<h2 id="Tokenization">Tokenization</h2>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=zduSFxRajkE">Recommended Resources</a></p>
<p>The tokenization includes the <strong>encoding and decoding process</strong> for the word list. We will focus on <strong>Byte-pair Encoding</strong> (BPE) for this section.</p>
<ul>
<li>
<p>Encoding: convert string to numbers</p>
</li>
<li>
<p>Decoding: convert numbers back to strings</p>
</li>
</ul>
<p>The vocabulary size is the number.</p>
<h3 id="Several-Notifications">Several Notifications</h3>
<ul>
<li>
<p>All the blank space are tokens</p>
</li>
<li>
<p>spaCy internally uses <strong>hash values to represent strings</strong>, and these hashes map to integer IDs.</p>
</li>
</ul>
<h3 id="BPE-tiktoken">BPE: <code>tiktoken</code></h3>
<p><code>tiktoken</code> is a tokenization tool trained by OpenAI with <strong>Byte-Pair Encoding</strong> (BPE), it achieves great achievement in English encoding and decoding.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tiktoken<br><br><span class="hljs-comment"># Choose an encoding that matches the models you might be using (e.g., for GPT-4, GPT-3.5-turbo)</span><br>encoding = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br>text_en = <span class="hljs-string">&quot;Hello, world! This is a test sentence for tiktoken.&quot;</span><br><br><span class="hljs-comment"># --- Encode (Text to Token IDs) ---</span><br><span class="hljs-comment"># encode() converts the string into a list of integer token IDs</span><br>token_ids_en = encoding.encode(text_en)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Original English Text: &#x27;<span class="hljs-subst">&#123;text_en&#125;</span>&#x27;&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Encoded Token IDs (English): <span class="hljs-subst">&#123;token_ids_en&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Number of tokens (English): <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(token_ids_en)&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># To see the actual tokens that correspond to the IDs (optional, for understanding)</span><br><span class="hljs-comment"># This requires decoding each ID individually or using a helper.</span><br><span class="hljs-comment"># Note: decoding individual IDs might not always yield readable strings if tokens are sub-word units.</span><br>decoded_parts_en = [encoding.decode([token_id]) <span class="hljs-keyword">for</span> token_id <span class="hljs-keyword">in</span> token_ids_en]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Decoded Parts (English, for understanding): <span class="hljs-subst">&#123;decoded_parts_en&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># --- Decode (Token IDs to Text) ---</span><br><span class="hljs-comment"># decode() converts a list of integer token IDs back into a string</span><br>decoded_text_en = encoding.decode(token_ids_en)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Decoded English Text: &#x27;<span class="hljs-subst">&#123;decoded_text_en&#125;</span>&#x27;&quot;</span>)<br><br>decoded_modified = [encoding.decode([token_id + <span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> token_id <span class="hljs-keyword">in</span> token_ids_en]<br><span class="hljs-built_in">print</span>(decoded_modified)<br><br><span class="hljs-comment"># Check if decoded text matches original (should be True)</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Decoded matches original? <span class="hljs-subst">&#123;decoded_text_en == text_en&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;After Modifications? <span class="hljs-subst">&#123;decoded_modified == text_en&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>The encoding and decoding process is a <strong>reversible process</strong>, for example, the <code>encoding_string</code> is a list of tokens which have been split, and generate a hash process to transform to a set of integer, which are called the <code>encoded_string</code>. The <strong>reversible</strong> part lies in that you can easily use <code>decode</code> method to generate the original <code>encoding_string</code>.</p>
<p><code>titoken</code> module is specifically designed for ASCII text (English), thus its support for CHinese and other unicode string is poor.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tiktoken<br><span class="hljs-comment"># tiktoken is for byte-pair encoding (BPE), Chinese is not supported.</span><br><br>test_strings = [<br>    <span class="hljs-string">&quot;Hello world, My name is Xiyuan Yang&quot;</span>,<br>    <span class="hljs-string">&quot;wow, it is so fantastic!&quot;</span>,<br>    <span class="hljs-string">&quot;你好，这里是中文，自古逢秋悲寂寥，我言秋日胜春朝&quot;</span>,<br>    <span class="hljs-string">&quot;international computational&quot;</span><br>]<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../../README.md&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    long_string = file.read()<br>    file.close()<br><span class="hljs-comment"># test_strings.append(long_string)</span><br>encoding = tiktoken.get_encoding(<span class="hljs-string">&quot;cl100k_base&quot;</span>)<br><br><span class="hljs-keyword">for</span> test_string <span class="hljs-keyword">in</span> test_strings:<br>    tokens = encoding.encode(test_string)<br>    num_bytes = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">bytes</span>(test_string, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>))<br>    <span class="hljs-comment"># print(num_bytes)</span><br>    num_tokens = <span class="hljs-built_in">len</span>(tokens)<br>    decoded = [encoding.decode([token]) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens]<br>    <span class="hljs-built_in">print</span>(decoded)<br>    <span class="hljs-built_in">print</span>(num_bytes / num_tokens)<br></code></pre></td></tr></table></figure>
<p>Let’s analyse the result:</p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>evluation</mtext><mo>=</mo><mfrac><mtext>num bytes</mtext><mtext>num tokens</mtext></mfrac></mrow><annotation encoding="application/x-tex">\text{evluation} = \frac{\text{num bytes}}{\text{num tokens}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">evluation</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">num tokens</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">num bytes</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<ul>
<li>
<p>For ANSCI, one single character is 1 bytes. (<code>char</code> in C++)</p>
</li>
<li>
<p>For Unicode, one single character is 3 bytes.</p>
</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">[&#x27;Hello&#x27;, &#x27; world&#x27;, &#x27;,&#x27;, &#x27; My&#x27;, &#x27; name&#x27;, &#x27; is&#x27;, &#x27; X&#x27;, &#x27;iy&#x27;, &#x27;uan&#x27;, &#x27; Yang&#x27;]<br>3.5<br>[&#x27;wow&#x27;, &#x27;,&#x27;, &#x27; it&#x27;, &#x27; is&#x27;, &#x27; so&#x27;, &#x27; fantastic&#x27;, &#x27;!&#x27;]<br>3.4285714285714284<br>[&#x27;你&#x27;, &#x27;好&#x27;, &#x27;，&#x27;, &#x27;这&#x27;, &#x27;里&#x27;, &#x27;是&#x27;, &#x27;中&#x27;, &#x27;文&#x27;, &#x27;，&#x27;, &#x27;自&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;，&#x27;, &#x27;我&#x27;, &#x27;言&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;日&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;, &#x27;�&#x27;]<br>2.057142857142857<br>[&#x27;international&#x27;, &#x27; computational&#x27;]<br>13.5<br></code></pre></td></tr></table></figure>
<ul>
<li>
<p>For the English word, the tokenization process is based on <strong>words</strong>, so <code>num_bytes/num_tokens</code> is mainly based on the average length of words.</p>
</li>
<li>
<p>For the Chinese word, the tokenization process is based on <strong>single characters</strong>.</p>
</li>
</ul>
<h3 id="Principles">Principles</h3>
<p>To make it more formalized: we want to find a hash function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>, given a list of unicode string: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">X = [x_1, x_2, \dots, x_n]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>, it satisfied:</p>
<ul>
<li>
<p>The set of the unicode string can be converted to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>y</mi><mi>m</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Y = [y_1, y_2, \dots, y_m]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>j</mi></msub><mo>=</mo><msub><mo>⋃</mo><mrow><mi>p</mi><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>q</mi></mrow></msub><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_j = \bigcup_{p \le i \le q}x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1858em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">⋃</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mrel mtight">≤</span><span class="mord mathnormal mtight">i</span><span class="mrel mtight">≤</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. (The splitting part, and we hope the splitting is meaningful, the value space of Y is the power set of the set composed of Unicode characters.)</p>
</li>
<li>
<p>The hash function: $f(y) = z, y \in \mathbb{Y}, z \in \mathbb{Z}, \mathbb{Z} \subseteq \mathbb{N} $.</p>
</li>
<li>
<p>No hash collision is allowed here. $\forall z \in \mathbb{Z}, \text{there exists only one } y \in \mathbb{Y}, f(y) = z $. (<strong>Injection is required</strong>)</p>
</li>
</ul>
<h4 id="Character-based-Tokenization">Character-based Tokenization</h4>
<p>For <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">Y</mi><mo>⊆</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>M</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{Y} \subseteq \mathcal{P}(M)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8249em;vertical-align:-0.136em;"></span><span class="mord mathbb">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⊆</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span> is finite, there exists at least one hash function that satisfy all the requirements above. A Unicode string is a sequence of Unicode characters. Each character can be converted into a code point (integer) via <code>ord</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> string<br><br>ord_result = [<span class="hljs-built_in">ord</span>(letter) <span class="hljs-keyword">for</span> letter <span class="hljs-keyword">in</span> string.ascii_letters]<br><span class="hljs-built_in">print</span>(ord_result)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">ord</span>(<span class="hljs-string">&quot;你&quot;</span>))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">ord</span>(<span class="hljs-string">&quot;,&quot;</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">ord</span>(<span class="hljs-string">&quot; &quot;</span>))<br><br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">ord</span>(<span class="hljs-string">&quot;Hello world&quot;</span>))<br><span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>    <span class="hljs-built_in">print</span>(e)<br><br><span class="hljs-comment"># [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]</span><br><span class="hljs-comment"># 20320</span><br><span class="hljs-comment"># 44</span><br><span class="hljs-comment"># 32</span><br><span class="hljs-comment"># ord() expected a character, but string of length 11 found</span><br></code></pre></td></tr></table></figure>
<p>The problems:</p>
<ul>
<li>
<p>The context meaning has been lost during the encoding process.</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="double-struck">Y</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|\mathbb{Y}|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathbb">Y</span><span class="mord">∣</span></span></span></span> is quite large, we need to make it smaller for the training process.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tokenizer</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Abstract interface for a tokenizer.&quot;&quot;&quot;</span><br><br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br>    <br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CharacterTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Represent a string as a sequence of Unicode code points.&quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">ord</span>, string))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>.join(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">chr</span>, indices))<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">string = <span class="hljs-string">&quot;自古逢秋悲寂寥，我言秋日胜春朝&quot;</span><br>tokenizer = CharacterTokenizer()<br><br>indices = tokenizer.encode(string)  <span class="hljs-comment"># @inspect indices</span><br>reconstructed_string = tokenizer.decode(indices)  <span class="hljs-comment"># @inspect reconstructed_string</span><br><br><span class="hljs-built_in">print</span>(indices)<br><span class="hljs-built_in">print</span>(reconstructed_string)<br><br><span class="hljs-keyword">assert</span> string == reconstructed_string<br>vocabulary_size = <span class="hljs-built_in">max</span>(indices) + <span class="hljs-number">1</span><br><span class="hljs-built_in">print</span>(vocabulary_size)<br></code></pre></td></tr></table></figure>
<h4 id="Byte-based-Tokenization">Byte-based Tokenization</h4>
<p>Unicode strings can be represented as a sequence of bytes, which can be represented by integers between 0 and 255.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ByteTokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Represent a string as a sequence of bytes.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        string_bytes = string.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)  <span class="hljs-comment"># @inspect string_bytes</span><br>        indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, string_bytes))  <span class="hljs-comment"># @inspect indices</span><br>        <span class="hljs-keyword">return</span> indices<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        string_bytes = <span class="hljs-built_in">bytes</span>(indices)  <span class="hljs-comment"># @inspect string_bytes</span><br>        string = string_bytes.decode(<span class="hljs-string">&quot;utf-8&quot;</span>)  <span class="hljs-comment"># @inspect string</span><br>        <span class="hljs-keyword">return</span> string<br><br>tokenizer = ByteTokenizer()<br><span class="hljs-built_in">print</span>(tokenizer.encode(<span class="hljs-string">&quot;自古逢秋悲寂寥，我言秋日胜春朝&quot;</span>))<br><span class="hljs-built_in">print</span>(tokenizer.decode(tokenizer.encode(<span class="hljs-string">&quot;自古逢秋悲寂寥，我言秋日胜春朝&quot;</span>)))<br></code></pre></td></tr></table></figure>
<p>Problem: quite long sequences.</p>
<h4 id="Word-based-Tokenization">Word-based Tokenization</h4>
<p>Use regex to split strings into word and do word-based tokenizations.</p>
<p>Problems:</p>
<ul>
<li>
<p>The number of words is huge (like for Unicode characters).</p>
</li>
<li>
<p>Many words are rare and the model won’t learn much about them.</p>
</li>
<li>
<p>This doesn’t obviously provide a fixed vocabulary size.</p>
</li>
</ul>
<h4 id="Byte-Pair-Encoding">Byte-Pair Encoding</h4>
<p>Wikipedia: <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Byte-pair_encoding">Byte Pair Encoding</a></p>
<p>The original paper: <a target="_blank" rel="noopener" href="http://www.pennelynn.com/Documents/CUJ/HTML/94HTML/19940045.HTM">http://www.pennelynn.com/Documents/CUJ/HTML/94HTML/19940045.HTM</a></p>
<p>It was adapted to NLP for neural machine translation.</p>
<div class="note note-primary">
            <p><strong>Neural Machine Translation of Rare Words with Subword Units</strong></p><p>Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as <strong>sequences of subword units</strong>. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character <em>n-gram</em> models and a segmentation based on the byte pair encoding compression algorithm.</p>
          </div>
<ul>
<li>Basic idea: train the tokenizer on raw text to automatically determine the vocabulary.</li>
<li>Intuition: common sequences of characters are represented by a single token, rare sequences are represented by many tokens.</li>
</ul>
<p>The GPT-2 paper used word-based tokenization to break up the text into inital segments and run the original BPE algorithm on each segment.</p>
<p>Sketch: start with each byte as a token, and <strong>successively merge the most common pair of adjacent tokens</strong>.</p>
<div class="note note-primary">
            <p>The BPE (Byte Pair Encoding) training process is an iterative algorithm that builds a vocabulary and a set of merge rules by finding and combining the most frequent adjacent symbols (bytes or subwords) in a given text.</p><ol><li><p><strong>Initialization:</strong></p><ul><li>Start with a <strong>vocabulary</strong> that contains all unique individual bytes (0-255) present in your training text.</li><li>Represent your training text as a sequence of these individual byte IDs.</li></ul></li><li><p><strong>Iterative Merging (for <code>N</code> desired merges):</strong></p><ul><li><strong>Count Pairs:</strong> In the current sequence of IDs (tokens), count the occurrences of all adjacent pairs of symbols.</li><li><strong>Find Most Frequent:</strong> Identify the pair of symbols that appears most frequently.</li><li><strong>Create New Symbol &amp; Rule:</strong><ul><li>Assign a <strong>new, unique ID</strong> to this most frequent pair (e.g., if IDs up to 255 are used for single bytes, start new IDs from 256).</li><li>Add this new ID to your <strong>vocabulary</strong>, mapping it to the combined byte sequence of the two symbols it represents (e.g., if <code>b'p'</code> and <code>b'a'</code> were merged, the new ID maps to <code>b'pa'</code>).</li><li>Record this <strong>merge rule</strong> (the original pair and its new ID).</li></ul></li><li><strong>Update Sequence:</strong> Replace all occurrences of the most frequent pair in your text sequence with the new symbol’s ID.</li></ul></li><li><p><strong>Repeat:</strong> Continue steps 2 until you’ve performed the desired number of merges (<code>N</code>) or no more pairs can be found.</p></li></ol><p>In essence, BPE training works by:</p><ul><li><strong>Starting small:</strong> Treating every byte as a distinct unit.</li><li><strong>Gradually expanding:</strong> Learning to combine frequently occurring sequences of bytes into new, larger “subwords.”</li><li><strong>Building a dictionary:</strong> Creating a mapping from these new subwords (and original bytes) to unique numerical IDs.</li></ul><p>This process allows the tokenizer to represent common words and subword units efficiently, leading to shorter token sequences for given texts, which is crucial for the performance of large language models.</p>
          </div>
<blockquote>
<p>Somehow like the process of Huffman Encoding.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">merge</span>(<span class="hljs-params"></span><br><span class="hljs-params">    indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>], pair: <span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>], new_index: <span class="hljs-built_in">int</span></span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:  <span class="hljs-comment"># @inspect indices, @inspect pair, @inspect new_index</span><br>    <span class="hljs-string">&quot;&quot;&quot;Return `indices`, but with all instances of `pair` replaced with `new_index`.&quot;&quot;&quot;</span><br>    new_indices = []  <span class="hljs-comment"># @inspect new_indices</span><br>    i = <span class="hljs-number">0</span>  <span class="hljs-comment"># @inspect i</span><br>    <span class="hljs-keyword">while</span> i &lt; <span class="hljs-built_in">len</span>(indices):<br>        <span class="hljs-keyword">if</span> i + <span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(indices) <span class="hljs-keyword">and</span> indices[i] == pair[<span class="hljs-number">0</span>] <span class="hljs-keyword">and</span> indices[i + <span class="hljs-number">1</span>] == pair[<span class="hljs-number">1</span>]:<br>            new_indices.append(new_index)<br>            i += <span class="hljs-number">2</span><br>        <span class="hljs-keyword">else</span>:<br>            new_indices.append(indices[i])<br>            i += <span class="hljs-number">1</span><br>    <span class="hljs-comment"># update the whole indices, thus it is very low</span><br>    <span class="hljs-keyword">return</span> new_indices<br><br><br><span class="hljs-meta">@dataclass(<span class="hljs-params">frozen=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BPETokenizerParams</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;All you need to specify a BPETokenizer.&quot;&quot;&quot;</span><br><br>    vocab: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">bytes</span>]  <span class="hljs-comment"># index -&gt; bytes</span><br>    merges: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>], <span class="hljs-built_in">int</span>]  <span class="hljs-comment"># index1, index2 -&gt; new_index</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BPETokenizer</span>(<span class="hljs-title class_ inherited__">Tokenizer</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;BPE tokenizer given a set of merges and a vocabulary.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, params: BPETokenizerParams</span>):<br>        <span class="hljs-variable language_">self</span>.params = params<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, string: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]:<br>        indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, string.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)))  <span class="hljs-comment"># @inspect indices</span><br>        <span class="hljs-comment"># Note: this is a very slow implementation</span><br>        <span class="hljs-comment"># simulate the whole merging process</span><br>        <span class="hljs-keyword">for</span> pair, new_index <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.params.merges.items():  <span class="hljs-comment"># @inspect pair, @inspect new_index</span><br>            indices = merge(indices, pair, new_index)<br>        <span class="hljs-keyword">return</span> indices<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, indices: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        bytes_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-variable language_">self</span>.params.vocab.get, indices))  <span class="hljs-comment"># @inspect bytes_list</span><br>        string = <span class="hljs-string">b&quot;&quot;</span>.join(bytes_list).decode(<span class="hljs-string">&quot;utf-8&quot;</span>)  <span class="hljs-comment"># @inspect string</span><br>        <span class="hljs-keyword">return</span> string<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_bpe</span>(<span class="hljs-params"></span><br><span class="hljs-params">    string: <span class="hljs-built_in">str</span>, num_merges: <span class="hljs-built_in">int</span></span><br><span class="hljs-params"></span>) -&gt; BPETokenizerParams:  <span class="hljs-comment"># @inspect string, @inspect num_merges</span><br>    <span class="hljs-comment"># Start with the list of bytes of string.</span><br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, string.encode(<span class="hljs-string">&quot;utf-8&quot;</span>)))  <span class="hljs-comment"># @inspect indices</span><br>    merges: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>], <span class="hljs-built_in">int</span>] = &#123;&#125;  <span class="hljs-comment"># index1, index2 =&gt; merged index</span><br><br>    <span class="hljs-comment"># initial vocab</span><br>    vocab: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">bytes</span>] = &#123;x: <span class="hljs-built_in">bytes</span>([x]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">256</span>)&#125;  <span class="hljs-comment"># index -&gt; bytes</span><br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_merges):<br>        <span class="hljs-comment"># Count the number of occurrences of each pair of tokens</span><br>        counts = defaultdict(<span class="hljs-built_in">int</span>)<br><br>        <span class="hljs-comment"># !really pythonic!</span><br>        <span class="hljs-keyword">for</span> index1, index2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(indices, indices[<span class="hljs-number">1</span>:]):  <span class="hljs-comment"># For each adjacent pair</span><br>            counts[(index1, index2)] += <span class="hljs-number">1</span>  <span class="hljs-comment"># @inspect counts</span><br>        <span class="hljs-comment"># Find the most common pair.</span><br>        pair = <span class="hljs-built_in">max</span>(counts, key=counts.get)  <span class="hljs-comment"># @inspect pair</span><br>        index1, index2 = pair<br>        <span class="hljs-comment"># Merge that pair.</span><br>        new_index = <span class="hljs-number">256</span> + i  <span class="hljs-comment"># @inspect new_index</span><br>        merges[pair] = new_index  <span class="hljs-comment"># @inspect merges</span><br>        vocab[new_index] = vocab[index1] + vocab[index2]  <span class="hljs-comment"># @inspect vocab</span><br>        indices = merge(indices, pair, new_index)  <span class="hljs-comment"># @inspect indices</span><br>    <span class="hljs-keyword">return</span> BPETokenizerParams(vocab=vocab, merges=merges)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">string = <span class="hljs-string">&quot;the cat in the hat&quot;</span>  <span class="hljs-comment"># @inspect string</span><br>params = train_bpe(string, num_merges=<span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(params)<br><br>tokenizer = BPETokenizer(params)<br>string = <span class="hljs-string">&quot;the quick brown fox&quot;</span>  <span class="hljs-comment"># @inspect string</span><br>indices = tokenizer.encode(string)  <span class="hljs-comment"># @inspect indices</span><br><span class="hljs-built_in">print</span>(indices)<br>reconstructed_string = tokenizer.decode(indices)  <span class="hljs-comment"># @inspect reconstructed_string</span><br><span class="hljs-keyword">assert</span> string == reconstructed_string<br></code></pre></td></tr></table></figure>
<p>For the data string provided and the <code>num_merges</code>, you can see the tokenize result.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># if you use different traning data?</span><br><br>params_2 = train_bpe(<span class="hljs-string">&quot;quick quick brown brown fox fox the the hfbdn ghdnb hfj&quot;</span>, num_merges=<span class="hljs-number">20</span>)<br>tokenizer_2 = BPETokenizer(params_2)<br>indices_2 = tokenizer_2.encode(string)<br><br><span class="hljs-built_in">print</span>(indices)<br><span class="hljs-built_in">print</span>(indices_2)<br><br><span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> indices:<br>    <span class="hljs-built_in">print</span>(tokenizer.decode([index]))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n&#x27;</span>)<br><br><span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> indices_2:<br>    <span class="hljs-built_in">print</span>(tokenizer_2.decode([index]))<br></code></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs text">[258, 113, 117, 105, 99, 107, 32, 98, 114, 111, 119, 110, 32, 102, 111, 120]<br>[271, 261, 265, 267]<br>the <br>q<br>u<br>i<br>c<br>k<br> <br>b<br>r<br>o<br>w<br>n<br> <br>f<br>o<br>x<br><br><br>the <br>quick <br>brown <br>fox<br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Artificial-Intelligence/" class="category-chain-item">Artificial Intelligence</a>
  
  
    <span>></span>
    
  <a href="/categories/Artificial-Intelligence/LLM/" class="category-chain-item">LLM</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Tutorial/" class="print-no-link">#Tutorial</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
        <a href="/tags/Tokenization/" class="print-no-link">#Tokenization</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>LLML CS336 Lecture 1 Overview and Tokenization</div>
      <div>https://xiyuanyang-code.github.io/posts/LLML-CS336-Lecture-1-Overview-and-Tokenization/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Xiyuan Yang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>July 28, 2025</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>August 1, 2025</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/LLML-CS336-Lecture-2-Pytorch-Resource-Accounting/" title="LLML CS336 Lecture 2 Pytorch Resource Accounting">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">LLML CS336 Lecture 2 Pytorch Resource Accounting</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/LLML-Transformer/" title="LLM Transformer">
                        <span class="hidden-mobile">LLM Transformer</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
    <div id="giscus" class="giscus"></div>
    <script type="text/javascript">
      Fluid.utils.loadComments('#giscus', function() {
        var options = {"repo":"xiyuanyang-code/xiyuanyang-code.github.io","repo-id":"R_kgDONRhvHQ","category":"Announcements","category-id":"DIC_kwDONRhvHc4ClBnp","theme-light":"light","theme-dark":"dark","mapping":"pathname","reactions-enabled":1,"emit-metadata":0,"input-position":"top","lang":"zh-CN"};
        var attributes = {};
        for (let option in options) {
          if (!option.startsWith('theme-')) {
            var key = option.startsWith('data-') ? option : 'data-' + option;
            attributes[key] = options[option];
          }
        }
        var light = 'light';
        var dark = 'dark';
        window.GiscusThemeLight = light;
        window.GiscusThemeDark = dark;
        attributes['data-theme'] = document.documentElement.getAttribute('data-user-color-scheme') === 'dark' ? dark : light;
        for (let attribute in attributes) {
          var value = attributes[attribute];
          if (value === undefined || value === null || value === '') {
            delete attributes[attribute];
          }
        }
        var s = document.createElement('script');
        s.setAttribute('src', 'https://giscus.app/client.js');
        s.setAttribute('crossorigin', 'anonymous');
        for (let attribute in attributes) {
          s.setAttribute(attribute, attributes[attribute]);
        }
        var ss = document.getElementsByTagName('script');
        var e = ss.length > 0 ? ss[ss.length - 1] : document.head || document.documentElement;
        e.parentNode.insertBefore(s, e.nextSibling);
      });
    </script>
    <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://github.com/xiyuanyang-code" target="_blank" rel="nofollow noopener"><span>YXY</span></a> <a href="https://xiyuanyang-code.github.io/Loving-Count/" target="_blank" rel="nofollow noopener"><span>❤️</span></a> <a href="https://github.com/Siyan-Li" target="_blank" rel="nofollow noopener"><span>LSY</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
