

<!DOCTYPE html>
<html lang="en" >



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/YXY.png">
  <link rel="icon" href="/img/YXY.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#c30000">
  <meta name="author" content="Xiyuan Yang">
  <meta name="keywords" content="Code">
  
    <meta name="description" content="A detailed explanation of the mathematical principles of convolutional neural networks.">
<meta property="og:type" content="article">
<meta property="og:title" content="ImageNet and ILSVRC">
<meta property="og:url" content="https://xiyuanyang-code.github.io/posts/Imagenet/index.html">
<meta property="og:site_name" content="Xiyuan Yang&#39;s Blog">
<meta property="og:description" content="A detailed explanation of the mathematical principles of convolutional neural networks.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://xiyuanyang-code.github.io/img/cover/AlexNet-1.jpg">
<meta property="article:published_time" content="2025-04-14T02:21:32.000Z">
<meta property="article:modified_time" content="2025-04-17T03:53:21.843Z">
<meta property="article:author" content="Xiyuan Yang">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Finished">
<meta property="article:tag" content="Convolutional Neural Networks">
<meta property="article:tag" content="AlexNet">
<meta property="article:tag" content="Image Clssification">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://xiyuanyang-code.github.io/img/cover/AlexNet-1.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ImageNet and ILSVRC - Xiyuan Yang&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xiyuanyang-code.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":50,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":"❡"},"progressbar":{"enable":true,"height_px":3,"color":"red","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":2},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"L7r0uGb0fafbzNvmBADCMH42-gzGzoHsz","app_key":"2Lr1fQ2rjhwRiUrDx0VOQyUm","server_url":null,"path":"window.location.pathname","ignore_local":true},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Xiyuan Yang&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/above/" target="_self">
                <i class="iconfont icon-bookmark-fill"></i>
                <span>Intro</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archive</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Category</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tag</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="https://xiyuanyang-code.github.io/My-Resume/" target="_self">
                <i class="iconfont icon-code"></i>
                <span>Resume</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>Else</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/FAQ/" target="_self">
                    <i class="iconfont icon-bug"></i>
                    <span>FAQ</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/links" target="_self">
                    <i class="iconfont icon-link-fill"></i>
                    <span>Links</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/All-posts/" target="_self">
                    <i class="iconfont icon-notebook"></i>
                    <span>All-posts</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/Recordings/" target="_self">
                    <i class="iconfont icon-clipcheck"></i>
                    <span>recordings</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/resume/" target="_self">
                    <i class="iconfont icon-github-fill"></i>
                    <span>Github Introduction</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://github.com/xiyuanyang-code" target="_self">
                    <i class="iconfont icon-github-fill"></i>
                    <span>My Github</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://hexo.fluid-dev.com/" target="_self">
                    <i class="iconfont icon-copyright"></i>
                    <span>About Hexo</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://xiyuanyang-code.github.io/posts/Life-musings/" target="_self">
                    <i class="iconfont icon-brush"></i>
                    <span>Life Musing</span>
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/place.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ImageNet and ILSVRC"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Xiyuan Yang
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-04-14 10:21" pubdate>
          April 14, 2025 am
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7k words
        
      </span>
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Artificial Intelligence"
        id="heading-5cd2adc9e2a5254e4c1da803519f298b" role="tab" data-toggle="collapse" href="#collapse-5cd2adc9e2a5254e4c1da803519f298b"
        aria-expanded="true"
      >
        Artificial Intelligence
        <span class="list-group-count">(11)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-5cd2adc9e2a5254e4c1da803519f298b"
           role="tabpanel" aria-labelledby="heading-5cd2adc9e2a5254e4c1da803519f298b">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/posts/CS294-1-LLM-Reasoning/" title="CS294-1-LLM-Reasoning"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">CS294-1-LLM-Reasoning</span>
        </a>
      
    
      
      
        <a href="/posts/CS294-3-Autogen/" title="CS294-3-Autogen"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">CS294-3-Autogen</span>
        </a>
      
    
      
      
        <a href="/posts/Pre-training-Is-Dead/" title="Pre-Training-Is-Dead?"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Pre-Training-Is-Dead?</span>
        </a>
      
    
      
      
        <a href="/posts/Deep-Learning-Memo/" title="Deep_Learning_Memo"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Deep_Learning_Memo</span>
        </a>
      
    
      
      
        <a href="/posts/RL-speeches/" title="RL_speeches"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">RL_speeches</span>
        </a>
      
    
      
      
        <a href="/posts/AI-Paper-2024/" title="AI-Paper-2024"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">AI-Paper-2024</span>
        </a>
      
    
      
      
        <a href="/posts/RAG-tutorial/" title="RAG-Tutorial"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">RAG-Tutorial</span>
        </a>
      
    
      
      
        <a href="/posts/AIBasis-Neural-Networks/" title="AIBasis_Neural_Networks"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">AIBasis_Neural_Networks</span>
        </a>
      
    
      
      
        <a href="/posts/Imagenet/" title="ImageNet and ILSVRC"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">ImageNet and ILSVRC</span>
        </a>
      
    
      
      
        <a href="/posts/AINN-Attention/" title="AINN Attention"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">AINN Attention</span>
        </a>
      
    
      
      
        <a href="/posts/AINN-Transformer/" title="AINN Transformer"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">AINN Transformer</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">ImageNet and ILSVRC</h1>
            
            
              <div class="markdown-body">
                
                <style>
  html, body, .markdown-body {
    font-family: Georgia, sans, serif;
  }
</style>
<h1 id="ImageNet-Classification-and-ILSVRC-Competition"><a href="#ImageNet-Classification-and-ILSVRC-Competition" class="headerlink" title="ImageNet Classification and ILSVRC Competition"></a>ImageNet Classification and ILSVRC Competition</h1><blockquote>
<p>My <strong>final assignment</strong> for <strong>Introduction to artificial intelligence</strong>.</p>
</blockquote>
<h1 id="Tracing-the-Evolution-of-ILSVRC-Winners-and-Their-Impact-on-Image-Classifications"><a href="#Tracing-the-Evolution-of-ILSVRC-Winners-and-Their-Impact-on-Image-Classifications" class="headerlink" title="Tracing the Evolution of ILSVRC Winners and Their Impact on Image Classifications"></a>Tracing the Evolution of ILSVRC Winners and Their Impact on Image Classifications</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>The past decade witnessed the transformation from Fully Connected Neural Network(FCNN) to Convolutional Neural Network(CNN) , which significantly addressed various challenges in the field of image recognition. This review traces how deep learning had passed a decade of breakthrough, introducing the evolution of winners from the <strong>ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</strong>, highlighting key advancements such as AlexNet, GoogLeNet, ResNet and ResNeXt. By analyzing the architectural innovations and methodological breakthroughs of these models such as ReLU, dropout, LRN, Inception, Residual Network and cardinality, the review then provides insights into the trends in neural network research, regarding how they implemented the optimization by adding the depth of the layers without introducing a huge amount of extra parameters and computational complexity. Finally, we discussed the outlook of Deep Neural Networks in the field of image classification, including striving for higher quality datasets, moving from object recognition to human-level understanding and finding alternative models outperforming traditional CNNs.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>再看卷积神经网络！在笔者大一上学期，曾经写过一篇有关<strong>ImageNet 和 ILSVRC</strong>相关的论文，当时属实是<strong>有一种掌握梯度下降就可以优化一切</strong>的傲气，如今回看这篇文章，颇觉得有许多需要改进的地方。因此，笔者决定<strong>重构</strong>这篇文章，并且从这篇文章出发，力求在数学上、工程上和思想上都对卷积神经网络有更深的理解。</p>
<p>回看当年<strong>炼丹</strong>的日子，或许在历史的长河中，我们总是<strong>能够找到新的灵感</strong>。</p>
<p>本博客的相关代码和文件将会存储在 <a target="_blank" rel="noopener" href="https://github.com/xiyuanyang-code/ImageNet-and-CNN-learning-materials">这个仓库</a> 中。坚持用中文，因为希望<strong>力求获得更加深刻的理解</strong>。</p>
<h2 id="从“卷积”谈起…"><a href="#从“卷积”谈起…" class="headerlink" title="从“卷积”谈起…"></a>从“卷积”谈起…</h2><p>给定两个函数$f(t)$和$g(t)$：</p>
<p>$$(f*g)(t)&#x3D;\int_{-\infty}^{+\infty}f(τ)g(t−\tau)\mathrm{d}τ$$</p>
<p>这个定义非常的抽象，我们不妨举一个<strong>形象化的例子</strong>：</p>
<h3 id="音频处理"><a href="#音频处理" class="headerlink" title="音频处理"></a>音频处理</h3><p>给定一个波形函数$f(t)$代表一段音频，现在，我们希望对这个函数做数学运算，来<strong>模拟回声</strong>的效果。</p>
<blockquote>
<p>这里其实暗含一个<strong>线性系统</strong>（线性时不变系统<strong>LTI</strong>）的假设，具体指的是：</p>
<ul>
<li><strong>线性</strong>：系统的输入和输出可以进行线性叠加。<ul>
<li>在这里，很显然两个波形函数叠加就可以得到新的函数。</li>
</ul>
</li>
<li><strong>时不变性</strong>：系统的输入输出关系不随时间变化。换句话说，如果输入信号的时间发生平移（延迟或提前），那么输出信号也会相应地平移相同的时间量，而不会改变其形状或性质。<ul>
<li>$ y(t)&#x3D;T[x(t)] \text{ then, }T[x(t−t_0)]&#x3D;y(t−t_0)$. 其中$T$代表系统的变化关系，$x(t)$和$y(t)$分别代表系统的输入和输出。</li>
<li>在这里，我们可以通过平移等手段实现这一点。（不深究）</li>
</ul>
</li>
</ul>
</blockquote>
<p>从直觉上，我们知道，如果在时间$t_0$处连续函数$f(t)$的函数值为$s_0 &#x3D; f(t_0)$，那么我们希望某种施加变换得到新函数$F(t)$，满足$F(t_0 + \delta) &#x3D; f(t_0 + \delta) + \epsilon f(t_0) $.</p>
<blockquote>
<p>这个公式直观意思：$t_0 + \delta$处的声音波形函数收到回声的影响（$t &#x3D; t_0$），使其分贝数（函数值）发生了变化。</p>
</blockquote>
<p>如何定量的表示这个函数？我们可以定义<strong>核函数</strong>$g(t)$，定义如下：<br>$$<br>g(t) &#x3D;<br>\begin{cases}<br>1, &amp; t &#x3D; 0 \\<br>\epsilon, &amp; t &#x3D; \delta \\<br>0, &amp; \text{otherwise}<br>\end{cases}<br>$$<br>这样我们就可以写出新的函数$F(t) &#x3D; (f*g)(t)&#x3D;\int_{0}^{t}f(τ)g(t−\tau)\mathrm{d}τ$。</p>
<blockquote>
<p>这个函数可以解释为：加入<strong>回声</strong>考虑之后，在$t$时刻的函数值（声音的分贝）可以解释为<strong>在过去每一个时刻发出声音</strong>的回声的<strong>线性叠加</strong>。因此，在实际我们可以将$g(t)$定义为更加复杂的衰减函数。</p>
</blockquote>
<p>这就是卷积！我们可以推广至更一般的情况，<strong>它的核心思想是通过一个滑动窗口（核函数）对输入数据进行加权求和，从而生成一个新的表示。</strong>例如在之前音频处理的例子中，核函数就是$g$，滑动窗口就是$\int_{0}^{t}$，我们对原始的输入数据$f(t)$进行加权求和，最终得到新的表示。</p>
<h3 id="卷积的可视化"><a href="#卷积的可视化" class="headerlink" title="卷积的可视化"></a>卷积的可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Author: Xiyuan Yang   xiyuan_yang@outlook.com</span><br><span class="hljs-string">Date: 2025-04-14 19:23:55</span><br><span class="hljs-string">LastEditors: Xiyuan Yang   xiyuan_yang@outlook.com</span><br><span class="hljs-string">LastEditTime: 2025-04-14 19:24:01</span><br><span class="hljs-string">FilePath: /CNN-tutorial/src/convolution.py</span><br><span class="hljs-string">Description:</span><br><span class="hljs-string">Do you code and make progress today?</span><br><span class="hljs-string">Copyright (c) 2025 by Xiyuan Yang, All Rights Reserved.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mlp<br><span class="hljs-keyword">from</span> scipy.integrate <span class="hljs-keyword">import</span> quad<br><br>mlp.use(<span class="hljs-string">&quot;Agg&quot;</span>)<br><br><br><span class="hljs-comment"># Original Function f(t)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">original_signal</span>(<span class="hljs-params">t</span>):<br>    <span class="hljs-keyword">return</span> np.sin(<span class="hljs-number">2</span> * np.pi * t)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">echo_kernel2</span>(<span class="hljs-params">t, alpha</span>):<br>    <span class="hljs-keyword">if</span> t &gt;= <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> np.exp(-alpha * t)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span><br><br><br><span class="hljs-comment"># Normalize the kernel to ensure its integral is 1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalized_echo_kernel</span>(<span class="hljs-params">t, alpha</span>):<br>    <span class="hljs-comment"># Compute the normalization factor (integral of the kernel from 0 to infinity)</span><br>    normalization_factor, _ = quad(<span class="hljs-keyword">lambda</span> tau: echo_kernel2(tau, alpha), <span class="hljs-number">0</span>, np.inf)<br>    <span class="hljs-comment"># Return the normalized kernel value</span><br>    <span class="hljs-keyword">return</span> echo_kernel2(t, alpha) / normalization_factor<br><br><br><span class="hljs-comment"># Convolution with normalized kernel</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convolution</span>(<span class="hljs-params">f, g, t_values, alpha</span>):<br>    h = []<br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> t_values:<br>        integral, _ = quad(<span class="hljs-keyword">lambda</span> tau: f(tau) * g(t - tau, alpha), <span class="hljs-number">0</span>, t)<br>        h.append(integral)<br>    <span class="hljs-keyword">return</span> np.array(h)<br><br><br><span class="hljs-comment"># Plot figure for two pictures</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plotfig</span>(<span class="hljs-params">t, f, h, alpha</span>):<br>    plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))<br>    <br>    <span class="hljs-comment"># Original Signal</span><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    plt.plot(t, f, label=<span class="hljs-string">&quot;Original Signal&quot;</span>, color=<span class="hljs-string">&quot;blue&quot;</span>)<br>    plt.title(<span class="hljs-string">&quot;Original Signal&quot;</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;Time (s)&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;Amplitude&quot;</span>)<br>    plt.legend()<br>    plt.grid()<br><br>    <span class="hljs-comment"># Signal with Continuous Echo Effect</span><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>    plt.plot(t, h, label=<span class="hljs-string">&quot;Signal with Continuous Echo&quot;</span>, color=<span class="hljs-string">&quot;red&quot;</span>)<br>    plt.title(<span class="hljs-string">&quot;Signal with Continuous Echo Effect&quot;</span>)<br>    plt.xlabel(<span class="hljs-string">&quot;Time (s)&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;Amplitude&quot;</span>)<br>    plt.legend()<br>    plt.grid()<br>    plt.tight_layout()<br>    plt.savefig(<span class="hljs-string">f&quot;img/Signal_with_Continuous_Effect_alpha=<span class="hljs-subst">&#123;alpha:<span class="hljs-number">.2</span>f&#125;</span>.png&quot;</span>)<br>    plt.close()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    t = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">500</span>)  <span class="hljs-comment"># Time range from 0 to 5 seconds</span><br>    f = original_signal(t)      <span class="hljs-comment"># Original signal</span><br>    <br>    <span class="hljs-comment"># Test different values of alpha</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">1.4</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2.5</span>, <span class="hljs-number">5</span>]:<br>        h = convolution(original_signal, normalized_echo_kernel, t, alpha=i)<br>        plotfig(t, f, h, i)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>

<p>随便选择一个$alpha$值，可以看到带着回声卷积处理之后的函数：</p>
<p><img src="https://s1.imagehub.cc/images/2025/04/15/2c9b576d8bde3d09dbd4c4ee58040077.png" srcset="/img/loading.gif" lazyload alt="卷积示例"></p>
<h2 id="卷积与图像"><a href="#卷积与图像" class="headerlink" title="卷积与图像"></a>卷积与图像</h2><p>我们知道，对于一张jpg图像可以把它转化为一个高维矩阵（每一个元素的值代表对应点的灰度大小）。但是对于<strong>自然世界中有意义的图像</strong>，矩阵在相邻位置的值往往具有<strong>一致性</strong>，比如色块和轮廓等。我们把这一特征抽象为<strong>图像中的关联性</strong>，相邻像素通常具有相似的灰度值或颜色（现实世界中物体表面的连续性和光照的平滑变化）。</p>
<p><img src="https://s1.imagehub.cc/images/2025/04/15/984fb8180a3715627a8214b8bbf62499.png" srcset="/img/loading.gif" lazyload alt="随机矩阵对应的雪花图"></p>
<p>并且，我们很明显知道，<strong>图像像素点之间的关联性</strong>很大程度上会随着距离的增加而衰减，我们可以使用常见的衰减模型来刻画这种衰减的状态：</p>
<p>指数衰减：$y &#x3D; e^{-kx}$ 或者 幂函数衰减：$y &#x3D; \frac{1}{x^k}$</p>
<p>同时，图像还满足多种<strong>不变性</strong>：平移不变性，旋转不变性，视点不变性，大小伸缩不变性…</p>
<p>因此，我们可以联想到，<strong>选择合适的核函数</strong>进行卷积运算是否可以实现图像特征的提取？答案是肯定的，我们不妨来看下面的例子：<strong>边缘检测</strong>。</p>
<h3 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h3><p><img src="https://s1.imagehub.cc/images/2025/04/15/339343f50534cbc97d20c228d803e8fc.png" srcset="/img/loading.gif" lazyload alt="image"></p>
<p>我们继续从<strong>音频识别</strong>的例子出发，卷积的本质就是<strong>加权平均</strong>，同时，图像相邻位置的像素点的值之间具有<strong>关联性</strong>，因此，我们可以使用**$3 \times 3$<strong>的卷积核，作为上文的卷积核函数。（这里是</strong>离散卷积**）</p>
<p>我们知道<strong>边缘</strong>区域代表着<strong>更加显著</strong>的亮度变化，因此，如果我们施加这样的卷积核：</p>
<p>$$\begin{bmatrix}-1 &amp; 0  &amp; 1 \\ -1 &amp; 0  &amp; 1 \\ -1 &amp; 0  &amp; 1 \end{bmatrix}$$</p>
<p><strong>负值区域</strong>（左侧）会对图像的亮度降低贡献较大，而<strong>正值区域</strong>（右侧）则会对亮度增加贡献较大。因此，就可以把对应的梯度特征给卷积出来，同理，我们也可以有对纵向的卷积核。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Author: Xiyuan Yang   xiyuan_yang@outlook.com</span><br><span class="hljs-string">Date: 2025-04-15 00:28:15</span><br><span class="hljs-string">LastEditors: Xiyuan Yang   xiyuan_yang@outlook.com</span><br><span class="hljs-string">LastEditTime: 2025-04-15 00:29:55</span><br><span class="hljs-string">FilePath: /CNN-tutorial/src/convolution_demo.py</span><br><span class="hljs-string">Description:</span><br><span class="hljs-string">Do you code and make progress today?</span><br><span class="hljs-string">Copyright (c) 2025 by Xiyuan Yang, All Rights Reserved.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mlp<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>mlp.use(<span class="hljs-string">&quot;Agg&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_convolution</span>(<span class="hljs-params">image_path, kernel, name</span>):<br>    <span class="hljs-comment"># 打开图片并转换为灰度图</span><br>    image = Image.<span class="hljs-built_in">open</span>(image_path).convert(<span class="hljs-string">&quot;L&quot;</span>)<br><br>    <span class="hljs-comment"># 转换为张量</span><br>    transform_to_tensor = transforms.ToTensor()<br>    image_tensor = transform_to_tensor(image).unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 增加批次维度 (1, 1, H, W)</span><br><br>    <span class="hljs-comment"># 卷积操作</span><br>    kernel_tensor = (<br>        torch.tensor(kernel, dtype=torch.float32).unsqueeze(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>)<br>    )  <span class="hljs-comment"># (1, 1, 3, 3)</span><br>    convolved_image = F.conv2d(image_tensor, kernel_tensor, padding=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 保持尺寸</span><br><br>    <span class="hljs-comment"># 转换回 NumPy 数组以便显示</span><br>    convolved_image_np = convolved_image.squeeze().detach().numpy()<br><br>    <span class="hljs-comment"># 显示原图和卷积后的图像</span><br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>    plt.title(<span class="hljs-string">&quot;Original Image&quot;</span>)<br>    plt.imshow(image, cmap=<span class="hljs-string">&quot;gray&quot;</span>)<br><br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>    plt.title(<span class="hljs-string">&quot;Convolved Image&quot;</span>)<br>    plt.imshow(convolved_image_np, cmap=<span class="hljs-string">&quot;gray&quot;</span>)<br>    plt.savefig(<span class="hljs-string">f&quot;img/Convolved_img <span class="hljs-subst">&#123;name&#125;</span>.png&quot;</span>)<br>    plt.close()<br><br><br><span class="hljs-comment"># 示例调用</span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># 定义 3x3 卷积核（例如边缘检测）</span><br>    kernel_1 = [[-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">8</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>]]<br>    kernel_2 = [[<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">5</span>, -<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]]<br>    kernel_3 = [[<span class="hljs-number">1</span> / <span class="hljs-number">9</span>, <span class="hljs-number">1</span> / <span class="hljs-number">9</span>, <span class="hljs-number">1</span> / <span class="hljs-number">9</span>], [<span class="hljs-number">1</span> / <span class="hljs-number">9</span>, <span class="hljs-number">1</span> / <span class="hljs-number">9</span>, <span class="hljs-number">1</span> / <span class="hljs-number">9</span>], [<span class="hljs-number">1</span> / <span class="hljs-number">9</span>, <span class="hljs-number">1</span> / <span class="hljs-number">9</span>, <span class="hljs-number">1</span> / <span class="hljs-number">9</span>]]<br>    kernel_4 = [[-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]]<br>    kernel_5 = np.random.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>    kernel_5 = kernel_5 / kernel_5.<span class="hljs-built_in">sum</span>()<br>    kernel_6 = np.identity(<span class="hljs-number">3</span>) / <span class="hljs-number">3</span><br>    kernel_7 = [[-<span class="hljs-number">2</span>, -<span class="hljs-number">3</span>, -<span class="hljs-number">2</span>], [-<span class="hljs-number">3</span>, <span class="hljs-number">21</span>, -<span class="hljs-number">3</span>], [-<span class="hljs-number">2</span>, -<span class="hljs-number">3</span>, -<span class="hljs-number">2</span>]]<br><br>    <span class="hljs-comment"># 替换为您本地的图片路径</span><br>    image_path = <span class="hljs-string">&quot;img/demo_cat.jpg&quot;</span>  <span class="hljs-comment"># 请确保路径正确</span><br>    apply_convolution(image_path, kernel_1, <span class="hljs-string">&quot;edge_detection&quot;</span>)<br>    apply_convolution(image_path, kernel_2, <span class="hljs-string">&quot;sharpen&quot;</span>)<br>    apply_convolution(image_path, kernel_3, <span class="hljs-string">&quot;normalize&quot;</span>)<br>    apply_convolution(image_path, kernel_4, <span class="hljs-string">&quot;edge_detect2&quot;</span>)<br>    apply_convolution(image_path, kernel_5, <span class="hljs-string">&quot;just for fun&quot;</span>)<br>    apply_convolution(image_path, kernel_6, <span class="hljs-string">&quot;kernel6&quot;</span>)<br>    apply_convolution(image_path, kernel_7, <span class="hljs-string">&quot;kernel_7&quot;</span>)<br><br>    <span class="hljs-comment"># the usage of surbo kernel</span><br>    kernel_surbo_1 = [[-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [-<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]]<br>    kernel_surbo_2 = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [-<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>, -<span class="hljs-number">2</span>]]<br>    apply_convolution(image_path, kernel_surbo_1, <span class="hljs-string">&quot;surbo_1&quot;</span>)<br>    apply_convolution(image_path, kernel_surbo_2, <span class="hljs-string">&quot;surbo_2&quot;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="卷积的数学运算"><a href="#卷积的数学运算" class="headerlink" title="卷积的数学运算"></a>卷积的数学运算</h3><p>在图像卷积中，我们会使用<strong>卷积函数的二维离散形式</strong>：</p>
<p>$$F(x,y) &#x3D; \sum_{u,v} f(x-u,y-v)g(u,v)$$</p>
<p>$$F(x,y) &#x3D; \int f(x-u,y-v)g(u,v) \mathrm{d}u \mathrm{d}v$$</p>
<p>这里$g(u,v)$代表我们之前使用的$3 \times 3$的卷积核。</p>
<p><img src="https://s1.imagehub.cc/images/2025/04/15/852f706ca8313ad8d5d81a1d0ed3c2b0.png" srcset="/img/loading.gif" lazyload alt="图像卷积的数学运算"></p>
<blockquote>
<p>这里就是一个非常经典的<strong>二维图像</strong>的滑动窗口！</p>
</blockquote>
<p>在卷积扫一遍之后，就会得到一张新的图像，这也就是我们上文展示的<strong>图像过卷积</strong>。</p>
<div class="note note-primary">
            <p><strong>Zero Padding</strong>：解决图像过卷积的问题</p><p>对于<strong>边缘</strong>的像素块，为了防止其在卷积之后被剪裁，我们需要<strong>适当扩展图像的size</strong>，例如这样：</p><p><img src="https://s1.imagehub.cc/images/2025/04/15/facae81e4da98908c65b8cb1ee318691.png" srcset="/img/loading.gif" lazyload alt="Zero Padding"></p>
          </div>

<p>在定义好卷积核函数之后（一个<strong>可训练的矩阵</strong>），我们终于可以<strong>移动滑动窗口</strong>了，这一个过程叫<strong>跨步（Stride）</strong>。$stride(i,j)$表示单次操作中横向移动$i$步，纵向移动$j$步。</p>
<p>同时，对于彩色图像，我们需要对RGB三个通道进行<strong>多通道卷积</strong>，不过为了简单起见，我们这里只考虑黑白单通道图像。</p>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>终于，我们迎来了今天的主角，<strong>卷积神经网络</strong>！</p>
<h4 id="生物学灵感"><a href="#生物学灵感" class="headerlink" title="生物学灵感"></a>生物学灵感</h4><p><strong>局部感受野</strong>：生物视觉系统中的神经元通常只对视野中的小区域敏感，这被称为局部感受野。CNN 中的卷积层通过卷积操作模拟了这一特性，允许网络在局部区域内提取特征。</p>
<p>因此，我们可以尝试<strong>将卷积结构带入到神经网络中</strong>，因为单纯的全连接网络在小数据量的情况下很容易过拟合，无法<strong>识别图像的真正特征</strong>。</p>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p>一个标准的卷积神经网络（Convolutional Neural Network, CNN）通常由以下几个模块构成：</p>
<ul>
<li>卷积层（Convolutional Layer） —— 简单细胞</li>
<li>池化层（Pooling Layer）</li>
<li>全连接层（Fully-Connected Layer）—— 复杂细胞</li>
<li>输出层（Output Layer）</li>
</ul>
<p>在接下来的部分，我们将具体介绍每一个网络层的应用。</p>
<h2 id="网络结构详解"><a href="#网络结构详解" class="headerlink" title="网络结构详解"></a>网络结构详解</h2><p>在这个部分，我们将会<strong>AlexNet</strong>为基础，介绍最基本的卷积神经网络的<strong>搭建</strong>和<strong>训练</strong>的过程。</p>
<p>先上代码（网络结构）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Author: Xiyuan Yang   xiyuan_yang@outlook.com</span><br><span class="hljs-string">Date: 2025-04-15 14:40:20</span><br><span class="hljs-string">LastEditors: Xiyuan Yang   xiyuan_yang@outlook.com</span><br><span class="hljs-string">LastEditTime: 2025-04-15 14:41:31</span><br><span class="hljs-string">FilePath: /CNN-tutorial/src/AlexNet.py</span><br><span class="hljs-string">Description:</span><br><span class="hljs-string">Do you code and make progress today?</span><br><span class="hljs-string">Copyright (c) 2025 by Xiyuan Yang, All Rights Reserved.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AlexNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes=<span class="hljs-number">1000</span></span>):<br>        <span class="hljs-built_in">super</span>(AlexNet, <span class="hljs-variable language_">self</span>).__init__()<br><br>        <span class="hljs-comment"># Define the convolutional layers</span><br>        <span class="hljs-variable language_">self</span>.features = nn.Sequential(<br>            <span class="hljs-comment"># First convolutional layer: 3 input channels, 64 output channels, kernel size 11x11, stride 4, padding 2</span><br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">11</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">2</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>            <span class="hljs-comment"># Second convolutional layer: 64 input channels, 192 output channels, kernel size 5x5, padding 2</span><br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>            <span class="hljs-comment"># Third convolutional layer: 192 input channels, 384 output channels, kernel size 3x3, padding 1</span><br>            nn.Conv2d(<span class="hljs-number">192</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            <span class="hljs-comment"># Fourth convolutional layer: 384 input channels, 256 output channels, kernel size 3x3, padding 1</span><br>            nn.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            <span class="hljs-comment"># Fifth convolutional layer: 256 input channels, 256 output channels, kernel size 3x3, padding 1</span><br>            nn.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>        )<br><br>        <span class="hljs-comment"># Define the fully connected layers</span><br>        <span class="hljs-variable language_">self</span>.classifier = nn.Sequential(<br>            nn.Dropout(),<br>            nn.Linear(<span class="hljs-number">256</span> * <span class="hljs-number">6</span> * <span class="hljs-number">6</span>, <span class="hljs-number">4096</span>),  <span class="hljs-comment"># Flattened feature map size is 256 * 6 * 6</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Dropout(),<br>            nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Linear(<span class="hljs-number">4096</span>, num_classes),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># Pass input through the convolutional layers</span><br>        x = <span class="hljs-variable language_">self</span>.features(x)<br><br>        <span class="hljs-comment"># Flatten the output for the fully connected layers</span><br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># Pass through the fully connected layers</span><br>        x = <span class="hljs-variable language_">self</span>.classifier(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-comment"># Example usage</span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># Create an instance of AlexNet with 1000 output classes (default for ImageNet)</span><br>    model = AlexNet(num_classes=<span class="hljs-number">1000</span>)<br><br>    <span class="hljs-comment"># Print the model architecture</span><br>    <span class="hljs-built_in">print</span>(model)<br><br>    <span class="hljs-comment"># Test with a random input tensor (batch size 1, 3 channels, 224x224 image)</span><br>    input_tensor = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br>    output = model(input_tensor)<br>    <span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># Should output torch.Size([1, 1000])</span><br><br></code></pre></td></tr></table></figure>

<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs routeros">AlexNet(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))<br>    (1): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>    (2): MaxPool2d(<span class="hljs-attribute">kernel_size</span>=3, <span class="hljs-attribute">stride</span>=2, <span class="hljs-attribute">padding</span>=0, <span class="hljs-attribute">dilation</span>=1, <span class="hljs-attribute">ceil_mode</span>=<span class="hljs-literal">False</span>)<br>    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))<br>    (4): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>    (5): MaxPool2d(<span class="hljs-attribute">kernel_size</span>=3, <span class="hljs-attribute">stride</span>=2, <span class="hljs-attribute">padding</span>=0, <span class="hljs-attribute">dilation</span>=1, <span class="hljs-attribute">ceil_mode</span>=<span class="hljs-literal">False</span>)<br>    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (7): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (9): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>    (12): MaxPool2d(<span class="hljs-attribute">kernel_size</span>=3, <span class="hljs-attribute">stride</span>=2, <span class="hljs-attribute">padding</span>=0, <span class="hljs-attribute">dilation</span>=1, <span class="hljs-attribute">ceil_mode</span>=<span class="hljs-literal">False</span>)<br>  )<br>  (classifier): Sequential(<br>    (0): Dropout(<span class="hljs-attribute">p</span>=0.5, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>    (1): Linear(<span class="hljs-attribute">in_features</span>=9216, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>    (2): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>    (3): Dropout(<span class="hljs-attribute">p</span>=0.5, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>    (4): Linear(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>    (5): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>    (6): Linear(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=1000, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>  )<br>)<br>torch.Size([1, 1000])<br></code></pre></td></tr></table></figure>

<h3 id="Input-Layer"><a href="#Input-Layer" class="headerlink" title="Input Layer"></a>Input Layer</h3><p>首先，对于一个CNN，输入是<strong>图片</strong>，单张图片embedding为矩阵的形式就是$224 \times 224 \times 3$的张量。（<strong>张量</strong>可以理解为是一种高维形式下的矩阵）。同时，模型可以一次输入<strong>多张图片</strong>，记为$N$,批量大小（同时处理的图片数量）。</p>
<div class="note note-info">
            <p>在深度学习中，通常用四个字母来表示<strong>多维张量的不同维度</strong>，尤其是在处理图像数据时。对于 AlexNet 输入的形状 ($N \times 224 \times 224 \times 3$)，这些字母通常代表：</p><ul><li><strong>N</strong>: Batch size（批量大小）—— 一次输入到网络中的样本数量。</li><li><strong>C</strong>: Channels（通道数）—— 通常对于 RGB 图像来说是 3（红、绿、蓝）。</li><li><strong>H</strong>: Height（高度）—— 图像的高度，这里是 224 像素。</li><li><strong>W</strong>: Width（宽度）—— 图像的宽度，这里也是 224 像素。</li></ul><p>因此，完整的表示可以是：</p><ul><li><strong>N</strong>: Batch size</li><li><strong>C</strong>: Channels</li><li><strong>H</strong>: Height</li><li><strong>W</strong>: Width</li></ul><p>在这种情况下，张量的形状可以表示为 ($N \times C \times H \times W$)，即 ($N \times 3 \times 224 \times 224$)。</p><p><strong>注意！</strong>批量指的是一次操作中输入的图片的数量，具体而言在训练细节中，指的是<strong>批量</strong>是指在一次前向传播和反向传播中处理的样本数量。比如，如果你有一个批量大小为 32 的训练集，那么在每次迭代中，模型将同时处理 32 张图像。批量反应的是<strong>GPU和模型并行处理图像的能力</strong>，但是对于网络结构而言，我们暂时不会考虑这一个参数（即每一次只研究一张图像）</p>
          </div>

<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>在输入层之后，就进入到了<code>Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))</code>的第一个卷积层。是一个$11 \times 11$的卷积核，$stride &#x3D; 4$（单次移动的步幅），同时会有一定的padding操作。</p>
<p>注意，这里还有一个参数<strong>64</strong>，代表着<strong>卷积核的通道数</strong>，换句话说可以理解为有多少个不同的卷积核在对这个图像做卷积。当我们说一个卷积层有 64 个输出通道时，意味着该层使用了 64 个卷积核。每个卷积核会生成一个特征图，所以最终会得到 64 个特征图。每个<strong>输出通道（特征图）</strong>捕捉输入数据的不同特征。例如，在图像处理中，一个卷积核可能专注于<strong>边缘检测</strong>，而另一个卷积核可能专注于<strong>纹理或颜色</strong>。</p>
<p>对于这个卷积层，其单个通道下的输出维度可以使用下面的函数进行计算：</p>
<p>$$Output Size&#x3D;\frac{Input Size−Kernel Size+2×Padding}{stride} + 1 &#x3D; 55$$</p>
<p>在这里，$Inputsize &#x3D; 224$, $KernelSize &#x3D; 11$, $Padding &#x3D; 2$, $stride &#x3D; 4$。</p>
<p>因此输出张量的维度 $(64,55,55)$。</p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>激活函数的作用，说到底就是在多层感知机线性的网络参数结构下引入<strong>非线性的部分</strong>，如果没有激活函数，神经网络的每一层其实都是线性变换，无法有效地拟合复杂的函数。同时，激活函数还可以有<strong>控制输出范围</strong>（$Sigmoid(x) &#x3D; \frac{1}{1+e^{-x}}$）、改善<strong>梯度消失现象</strong>（$Tanh(x) &#x3D; \frac{e^x - e^{-x}}{e^x + e^{-x}}$）的作用。</p>
<p>$$ReLU(x) &#x3D; \begin{cases}<br>0, &amp; x \le 0 \\<br>x, &amp; x &gt; 0<br>\end{cases}$$</p>
<p>在这里<strong>ReLU</strong>是一个非线性的激活函数，并且由于负值被截断为零，ReLU 使得一部分<strong>神经元在某些输入下不激活</strong>（输出为零），这有助于模型的稀疏性和提高计算效率（ReLU的计算非常简单）。</p>
<p><code>inplace=True</code> 表示在原地进行操作。这意味着 ReLU 函数会直接修改输入张量，而不是创建一个新的张量来存储输出。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>在经过ReLU函数激活之后，我们来到了<strong>池化层</strong>：<code>nn.MaxPool2d(kernel_size=3, stride=2)</code>。在讲解这个操作之前，我们先来具体了解一下什么是<strong>池化</strong>。</p>
<p>在不同的网络层数之间，我们储存的都是<strong>矩阵</strong>，而这些矩阵都是<strong>非常稀疏</strong>的矩阵，或者说这些矩阵内部非常多的元素都是0，尤其是在经过多次ReLU激活之后，这样会带来好处（<strong>详见高维数据的处理：高维空间下向量近似正交</strong>）。但是这对<strong>数据的存储和计算效率上带来了很大的困难</strong>，因此，为了进一步压缩<strong>图像卷积提取到的图片特征</strong>，我们需要对特征图进行进一步的压缩。这一步过程就叫做<strong>池化</strong>（也可以叫做<strong>下采样</strong>）。</p>
<ul>
<li><strong>降维</strong>: 池化可以减少特征图的尺寸，从而降低后续层的计算复杂度。</li>
<li><strong>特征提取</strong>: 通过选择特定区域内的最大值或平均值，池化能够保留重要的特征，同时抑制噪声。</li>
<li><strong>防止过拟合</strong>: 通过减少特征图的尺寸，池化有助于减少模型的复杂性，从而降低过拟合的风险。</li>
</ul>
<p>池化的具体操作非常简单，主要分为<strong>最大池化（Max Pooling）和平均池化（Average Pooling）</strong>：</p>
<ul>
<li><strong>最大池化（Max Pooling）</strong>: 在池化窗口内选<strong>择最大值。它能够保留特征图中的重要信息</strong>，尤其是在图像处理中。</li>
<li><strong>平均池化（Average Pooling）</strong>: 在池化窗口内<strong>计算平均值</strong>。它对特征图的平滑效果更强，但可能会丢失一些重要的特征。</li>
</ul>
<p>池化过程中的参数有：</p>
<ul>
<li><strong>池化窗口大小（Kernel Size）</strong>: 池化操作中使用的窗口的大小，例如 2×22×2 或 3×33×3。</li>
<li><strong>步幅（Stride）</strong>: 池化窗口在特征图上移动的步长。步幅越大，输出特征图的尺寸越小。</li>
<li><strong>填充（Padding）</strong>: 在某些情况下，可以在特征图的边缘添加额外的像素，以控制输出尺寸。</li>
</ul>
<p>因此，我们便可以理解这一行代码是什么意思了：使用<strong>最大池化</strong>。其对应参数的解释：</p>
<ul>
<li><p><code>dilation=1</code></p>
<ul>
<li><p><strong>含义</strong>: 控制池化窗口元素之间的间距。</p>
</li>
<li><p><strong>解释</strong>: <code>dilation=1</code> 表示池化窗口的元素之间没有间隔，窗口是紧凑的。增加 <code>dilation</code> 值会使得窗口的元素之间有间隔，这在某些情况下可以用于扩大感受野。</p>
</li>
</ul>
</li>
<li><p><code>ceil_mode=False</code></p>
<ul>
<li><strong>含义</strong>: 控制输出特征图尺寸的计算方式。</li>
<li><strong>解释</strong>: <code>ceil_mode=False</code> 表示在计算输出特征图的尺寸时使用向下取整（floor）。如果设置为 <code>True</code>，则使用向上取整（ceil），这可能会导致输出特征图的尺寸略微增大。</li>
</ul>
</li>
</ul>
<p>假设有一个输入特征图，其尺寸为 $H×W$，经过池化操作后，输出特征图的尺寸可以通过以下公式计算：</p>
<p>$$Output Height&#x3D;⌊\frac{H−kernel_size}{stride}+1⌋$$</p>
<p>$$Output Width&#x3D;⌊\frac{W−kernel_size}{stride}+1⌋$$</p>
<div class="note note-primary">
            <p>学习完这三个层之后，你应该就可以看懂下面的代码了：（<strong>当然也是上面的代码</strong>）</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs routeros">(features): Sequential(<br>   (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))<br>   (1): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>   (2): MaxPool2d(<span class="hljs-attribute">kernel_size</span>=3, <span class="hljs-attribute">stride</span>=2, <span class="hljs-attribute">padding</span>=0, <span class="hljs-attribute">dilation</span>=1, <span class="hljs-attribute">ceil_mode</span>=<span class="hljs-literal">False</span>)<br>   (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))<br>   (4): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>   (5): MaxPool2d(<span class="hljs-attribute">kernel_size</span>=3, <span class="hljs-attribute">stride</span>=2, <span class="hljs-attribute">padding</span>=0, <span class="hljs-attribute">dilation</span>=1, <span class="hljs-attribute">ceil_mode</span>=<span class="hljs-literal">False</span>)<br>   (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>   (7): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>   (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>   (9): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>   (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>   (11): ReLU(<span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br>   (12): MaxPool2d(<span class="hljs-attribute">kernel_size</span>=3, <span class="hljs-attribute">stride</span>=2, <span class="hljs-attribute">padding</span>=0, <span class="hljs-attribute">dilation</span>=1, <span class="hljs-attribute">ceil_mode</span>=<span class="hljs-literal">False</span>)<br> )<br></code></pre></td></tr></table></figure>
          </div>

<p>不过接下来AlexNet还没有结束！让我们继续往下看：</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>在AlexNet类中的前向传播的函数中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-comment"># Pass input through the convolutional layers</span><br>    x = <span class="hljs-variable language_">self</span>.features(x)<br><br>    <span class="hljs-comment"># Flatten the output for the fully connected layers</span><br>    x = torch.flatten(x, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># Pass through the fully connected layers</span><br>    x = <span class="hljs-variable language_">self</span>.classifier(x)<br>    <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>

<p>输入的向量$x$首先经过<code>self.features()</code>即若干个卷积层的处理之后，又经过<code>torch.flatten(x,1)</code>，展平为<strong>一维向量</strong>。接下来，AlexNet使用了一个传统的全连接神经网络，来拟合在提取和抽象过后图像矩阵的信息，即<code>x = self.classifier(x)</code>。</p>
<div class="note note-primary">
            <p><strong>严格来说</strong>，并非展平为一维向量，因为还有<strong>通道数</strong>($N$)。</p><p><code>torch.flatten</code> 函数用于将输入张量展平为一维张量。它可以选择性地从某个特定维度开始展平。</p><ul><li><strong>第一个参数</strong>: <code>x</code> 是要展平的输入张量，通常是一个多维张量，例如卷积层的输出。</li><li><strong>第二个参数</strong>: <code>1</code> 指定从哪个维度开始展平。这意味着在维度 1 及其之后的所有维度都将被展平，而维度 0（通常是批量大小）将保持不变。</li></ul><p>假设 <code>x</code> 是一个形状为 <code>(batch_size, channels, height, width)</code> 的四维张量（例如，来自卷积层的输出）。在这种情况下：</p><ul><li><code>batch_size</code> 表示一次处理的样本数。</li><li><code>channels</code> 是特征图的通道数（例如，256）。</li><li><code>height</code> 和 <code>width</code> 是特征图的空间维度（例如，6 和 6）。</li></ul><p>当你调用 <code>torch.flatten(x, 1)</code> 时，结果将是一个形状为 <code>(batch_size, channels * height * width)</code> 的二维张量。具体来说，如果 <code>x</code> 的形状是 <code>(N, 256, 6, 6)</code>，那么展平后它的形状将变为 <code>(N, 256 * 6 * 6)</code>，即 <code>(N, 9216)</code>。</p>
          </div>

<p>我们来看全连接层的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Define the fully connected layers</span><br>        <span class="hljs-variable language_">self</span>.classifier = nn.Sequential(<br>            nn.Dropout(),<br>            nn.Linear(<span class="hljs-number">256</span> * <span class="hljs-number">6</span> * <span class="hljs-number">6</span>, <span class="hljs-number">4096</span>),  <span class="hljs-comment"># Flattened feature map size is 256 * 6 * 6</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Dropout(),<br>            nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Linear(<span class="hljs-number">4096</span>, num_classes),<br>        )<br></code></pre></td></tr></table></figure>

<h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p><code>Dropout</code>技术是AlexNet的首创，它在训练过程中随机地“丢弃”网络中的一部分神经元，以减少模型对特定神经元的依赖，从而提高模型的<strong>泛化能力</strong>（防止过拟合）。具体而言，在每次训练迭代中，Dropout 会以一定的概率（通常在 0.2 到 0.5 之间）随机选择一些神经元，并将它们的输出设为零。这意味着这些神经元在这一轮训练中不会参与计算。</p>
<p><code>nn.Linear(256 * 6 * 6, 4096)</code>代表输入被展平为一个$256<em>6</em>6&#x3D;9216$的高维向量，并通过一次全连接的神经网络，最终输出的维度是$4096$维的向量。</p>
<p>最终经过多层线性全连接层的拟合之后，函数终于来到了最后一层。</p>
<h3 id="Output-Layer"><a href="#Output-Layer" class="headerlink" title="Output Layer"></a>Output Layer</h3><p><code>nn.Linear(4096, num_classes)</code>，将 4096 维的特征向量转换为 <code>num_classes</code> 维的输出，网络能够为每个类别生成一个分数。通常，这些分数会通过 softmax 函数进行归一化，以便将它们转换为概率值。</p>
<blockquote>
<p>在 PyTorch 中，通常在训练和推理阶段，softmax 操作会在损失计算时进行，而不是直接在模型结构中实现。这种做法可以避免在训练过程中出现数值不稳定的问题。</p>
</blockquote>
<h2 id="Train-The-Model"><a href="#Train-The-Model" class="headerlink" title="Train The Model!"></a>Train The Model!</h2><p>我们已经实现了卷积神经网络的<strong>正向传播函数</strong>，关键在于如何训练这个神经网络？</p>
<ul>
<li>对于全连接层，使用正常的<strong>梯度下降</strong>。</li>
<li>对于卷积层，<strong>基本思路</strong>保持不变，在每一次迭代的过程中，比较$Y$与卷积层输出的误差平方，然后使用梯度下降来更新卷积核矩阵的参数。</li>
<li>对于池化层，如果是最大池化，只更新单个的值，如果是平均池化，需要更新卷积核对应每一个元素的值。</li>
</ul>
<p>我们可以使用Python来实现CNN（AlexNet）的预训练过程，我们使用cifar10数据集。</p>
<h2 id="Demonstrations"><a href="#Demonstrations" class="headerlink" title="Demonstrations"></a>Demonstrations</h2><p>在接下来的文件中，我们需要使用上面定义的AlexNet网络结构，来训练神经网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Train the Basic Alexnet: session BEGIN&quot;</span>)<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><span class="hljs-keyword">from</span> AlexNet <span class="hljs-keyword">import</span> AlexNet<br><br><span class="hljs-comment"># Check if GPU is available</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-comment"># Hyperparameters</span><br>batch_size = <span class="hljs-number">128</span><br>learning_rate = <span class="hljs-number">0.001</span><br>num_epochs = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># Data preprocessing and augmentation</span><br>transform = transforms.Compose([<br>    transforms.RandomHorizontalFlip(),<br>    transforms.RandomCrop(<span class="hljs-number">32</span>, padding=<span class="hljs-number">4</span>),<br>    transforms.ToTensor(),<br>    transforms.Normalize((<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.4822</span>, <span class="hljs-number">0.4465</span>), (<span class="hljs-number">0.2023</span>, <span class="hljs-number">0.1994</span>, <span class="hljs-number">0.2010</span>)),<br>])<br><br><span class="hljs-comment"># Load CIFAR-10 dataset</span><br>train_dataset = datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>test_dataset = datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br><br>train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">4</span>)<br>test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">4</span>)<br><br><span class="hljs-comment"># Initialize the model</span><br>model = AlexNet(num_classes=<span class="hljs-number">10</span>)  <span class="hljs-comment"># CIFAR-10 has 10 classes</span><br><br><span class="hljs-comment"># Use multiple GPUs if available</span><br><span class="hljs-keyword">if</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Using <span class="hljs-subst">&#123;torch.cuda.device_count()&#125;</span> GPUs&quot;</span>)<br>    model = nn.DataParallel(model)<br><br>model = model.to(device)<br><br><span class="hljs-comment"># Define loss function and optimizer</span><br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.Adam(model.parameters(), lr=learning_rate)<br><br><span class="hljs-comment"># Training loop</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    model.train()<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        running_loss = <span class="hljs-number">0.0</span><br>        <span class="hljs-keyword">for</span> i, (inputs, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>            inputs, labels = inputs.to(device), labels.to(device)<br><br>            <span class="hljs-comment"># Zero the parameter gradients</span><br>            optimizer.zero_grad()<br><br>            <span class="hljs-comment"># Forward pass</span><br>            outputs = model(inputs)<br>            loss = criterion(outputs, labels)<br><br>            <span class="hljs-comment"># Backward pass and optimization</span><br>            loss.backward()<br>            optimizer.step()<br><br>            running_loss += loss.item()<br>            <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:  <span class="hljs-comment"># Print every 100 batches</span><br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch [<span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_epochs&#125;</span>], Step [<span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(train_loader)&#125;</span>], Loss: <span class="hljs-subst">&#123;running_loss / <span class="hljs-number">100</span>:<span class="hljs-number">.4</span>f&#125;</span>&quot;</span>)<br>                running_loss = <span class="hljs-number">0.0</span><br><br><span class="hljs-comment"># Testing loop</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> test_loader:<br>            inputs, labels = inputs.to(device), labels.to(device)<br>            outputs = model(inputs)<br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br>            total += labels.size(<span class="hljs-number">0</span>)<br>            correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Accuracy on test set: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * correct / total:<span class="hljs-number">.2</span>f&#125;</span>%&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    train()<br>    test()<br></code></pre></td></tr></table></figure>

<h3 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h3><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs prolog"><span class="hljs-symbol">Train</span> the <span class="hljs-symbol">Basic</span> <span class="hljs-symbol">Alexnet</span>: session <span class="hljs-symbol">BEGIN</span><br><span class="hljs-symbol">Using</span> <span class="hljs-number">8</span> <span class="hljs-symbol">GPUs</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">1</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">2.0992</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">1</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.8165</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">1</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.6880</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">2</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.5118</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">2</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.4040</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">2</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.3631</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">3</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.2742</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">3</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.1991</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">3</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.1774</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">4</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.1276</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">4</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.1034</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">4</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.0797</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">5</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.0207</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">5</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.0175</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">5</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">1.0079</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">6</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.9821</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">6</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.9552</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">6</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.9217</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">7</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8774</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">7</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8826</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">7</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8886</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">8</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8533</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">8</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8324</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">8</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8523</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">9</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.7809</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">9</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8207</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">9</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.8053</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">10</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">100</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.7702</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">10</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">200</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.7630</span><br><span class="hljs-symbol">Epoch</span> [<span class="hljs-number">10</span>/<span class="hljs-number">10</span>], <span class="hljs-symbol">Step</span> [<span class="hljs-number">300</span>/<span class="hljs-number">391</span>], <span class="hljs-symbol">Loss</span>: <span class="hljs-number">0.7576</span><br><span class="hljs-symbol">Accuracy</span> on test set: <span class="hljs-number">73.22</span><span class="hljs-comment">%</span><br></code></pre></td></tr></table></figure>

<div class="note note-primary">
            <p><strong>报错了？</strong>我们需要做一些修改！</p><p><strong>输入图像的大小与 AlexNet 的架构</strong>不匹配导致的。AlexNet 的设计是基于 ImageNet 数据集的输入图像大小（224x224）。而 CIFAR-10 数据集的图像大小是 32x32，经过 AlexNet 的卷积层和池化层后，特征图的大小变为 0，导致错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AlexNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes=<span class="hljs-number">10</span></span>):  <span class="hljs-comment"># CIFAR-10 has 10 classes</span><br>        <span class="hljs-built_in">super</span>(AlexNet, <span class="hljs-variable language_">self</span>).__init__()<br><br>        <span class="hljs-comment"># Define the convolutional layers</span><br>        <span class="hljs-variable language_">self</span>.features = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),  <span class="hljs-comment"># Adjusted for 32x32 input</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># Output: 16x16</span><br><br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># Output: 8x8</span><br><br>            nn.Conv2d(<span class="hljs-number">192</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br><br>            nn.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># Output: 4x4</span><br>        )<br><br>        <span class="hljs-comment"># Define the fully connected layers</span><br>        <span class="hljs-variable language_">self</span>.classifier = nn.Sequential(<br>            nn.Dropout(),<br>            nn.Linear(<span class="hljs-number">256</span> * <span class="hljs-number">4</span> * <span class="hljs-number">4</span>, <span class="hljs-number">4096</span>),  <span class="hljs-comment"># Adjusted for 4x4 feature map</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Dropout(),<br>            nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Linear(<span class="hljs-number">4096</span>, num_classes),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.features(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = <span class="hljs-variable language_">self</span>.classifier(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>
          </div>

<h3 id="Something-Else"><a href="#Something-Else" class="headerlink" title="Something Else"></a>Something Else</h3><p>我们不妨问这样一个问题，<strong>在AlexNet的学习过程中，模型学习到了什么？</strong></p>
<p>来看论文原文，Ilya是这样写的：</p>
<p><img src="https://s1.imagehub.cc/images/2025/04/17/26604bda8b8525b7d2d507b3d98c4c36.png" srcset="/img/loading.gif" lazyload alt="Details of Learning"></p>
<p>Figure 3 shows the convolutional kernels learned by the network’s two data-connected layers. The network has learned <strong>a variety of frequency and orientation-selective kernels</strong>, as well as various colored blobs. Notice the specialization exhibited by the two GPUs, a result of the restricted connectivity described in Section 3.5. The kernels on GPU 1 are largely <strong>color-agnostic,</strong> while the kernels on on GPU 2 are largely <strong>color-specific</strong>. This kind of specialization occurs during every run and is independent of any particular random weight initialization (modulo a renumbering of the GPUs).</p>
<p>AlexNet 由于受限于当时GPU能力的限制，采用了<strong>GPU并行训练</strong>的方法，正如下面的图：</p>
<p><img src="https://s1.imagehub.cc/images/2025/04/17/5cbb1e56d8ddde319055009365e19819.png" srcset="/img/loading.gif" lazyload alt="AlexNet"></p>
<h2 id="Variant"><a href="#Variant" class="headerlink" title="Variant"></a>Variant</h2><p>在2012年的ImageNet图像识别竞赛中，AlexNet <strong>一战成名</strong>，以极大的优势豪取第一名，并从此掀起了深度学习的热潮。但是人类探索的脚步不止于此！在之后的七届竞赛中，<strong>更多更加新颖更加复杂的网络结构</strong>不断被设计出来，在测试机上的表现高于AlexNet！</p>
<p>他们包括：</p>
<ul>
<li>使用重复块的网络（VGG）</li>
<li>网络中的网络（NiN）</li>
<li>GoogLenet</li>
<li>ResNet &amp; ResNeXt（<strong>残差神经网络</strong>）</li>
<li>DenseNet</li>
</ul>
<p>这一部分的内容也非常的精彩，不过在这里就不介绍啦~</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文主要以<strong>AlexNet</strong>为载体介绍了<strong>最基本且传统的卷积神经网络架构</strong>，从卷积的数学原理和定义出发，再到卷积神经网络的卷积层、池化层和全连接层等。在讲解完卷积神经网络的网络结构之后，有深入分析了卷积神经网络的训练细节，以及卷积核的可视化过程。</p>
<blockquote>
<p>内容相对比较基础，但是一切的灵感都建立在扎实的基础之上，不是吗？</p>
</blockquote>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Artificial-Intelligence/" class="category-chain-item">Artificial Intelligence</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Artificial-Intelligence/" class="print-no-link">#Artificial Intelligence</a>
      
        <a href="/tags/Deep-Learning/" class="print-no-link">#Deep Learning</a>
      
        <a href="/tags/Finished/" class="print-no-link">#Finished</a>
      
        <a href="/tags/Convolutional-Neural-Networks/" class="print-no-link">#Convolutional Neural Networks</a>
      
        <a href="/tags/AlexNet/" class="print-no-link">#AlexNet</a>
      
        <a href="/tags/Image-Clssification/" class="print-no-link">#Image Clssification</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ImageNet and ILSVRC</div>
      <div>https://xiyuanyang-code.github.io/posts/Imagenet/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Xiyuan Yang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>April 14, 2025</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>April 17, 2025</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/DataStructure-Splay-Tree/" title="DataStructure Splay Tree">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">DataStructure Splay Tree</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/Modern-C/" title="Modern C++">
                        <span class="hidden-mobile">Modern C++</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
    <div id="giscus" class="giscus"></div>
    <script type="text/javascript">
      Fluid.utils.loadComments('#giscus', function() {
        var options = {"repo":"xiyuanyang-code/xiyuanyang-code.github.io","repo-id":"R_kgDONRhvHQ","category":"Announcements","category-id":"DIC_kwDONRhvHc4ClBnp","theme-light":"light","theme-dark":"dark","mapping":"pathname","reactions-enabled":1,"emit-metadata":0,"input-position":"top","lang":"zh-CN"};
        var attributes = {};
        for (let option in options) {
          if (!option.startsWith('theme-')) {
            var key = option.startsWith('data-') ? option : 'data-' + option;
            attributes[key] = options[option];
          }
        }
        var light = 'light';
        var dark = 'dark';
        window.GiscusThemeLight = light;
        window.GiscusThemeDark = dark;
        attributes['data-theme'] = document.documentElement.getAttribute('data-user-color-scheme') === 'dark' ? dark : light;
        for (let attribute in attributes) {
          var value = attributes[attribute];
          if (value === undefined || value === null || value === '') {
            delete attributes[attribute];
          }
        }
        var s = document.createElement('script');
        s.setAttribute('src', 'https://giscus.app/client.js');
        s.setAttribute('crossorigin', 'anonymous');
        for (let attribute in attributes) {
          s.setAttribute(attribute, attributes[attribute]);
        }
        var ss = document.getElementsByTagName('script');
        var e = ss.length > 0 ? ss[ss.length - 1] : document.head || document.documentElement;
        e.parentNode.insertBefore(s, e.nextSibling);
      });
    </script>
    <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://github.com/xiyuanyang-code" target="_blank" rel="nofollow noopener"><span>YXY</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/Siyan-Li" target="_blank" rel="nofollow noopener"><span>LSY</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
